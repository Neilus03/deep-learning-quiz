<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>DEEP LEARNING QUIZ</title>
<style>
  body {
    font-family: Arial, Helvetica, sans-serif;
  }

  h1 {
    text-align: center;
  }

  button {
    margin: 5px;
    padding: 10px;
    font-size: 16px;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    transition: all 0.2s ease-in-out;
  }

  button:hover {
    opacity: 0.8;
  }

  .question-container {
    margin-bottom: 20px;
    padding: 20px;
    border: 1px solid #ccc;
    border-radius: 10px;
  }

  .question {
    margin-bottom: 10px;
    font-size: 18px;
    font-weight: bold;
  }

  .answer-button {
    background-color: #fff;
    color: #333;
  }

  .correct-button {
    background-color: #5cb85c;
    color: #fff;
  }

  .incorrect-button {
    background-color: #d9534f;
    color: #fff;
  }
</style>
<script>
  const questions = [
    {
    question: "1.1 A feed-forward neural network with a single hidden layer and a sufficient number of hidden neurons can approximate any continuous function.",
    answer: "True"
  },
  {
    question: "1.2 Leaky ReLU activation functions are more likely to suffer from the vanishing gradient problem compared to sigmoid activation functions.",
    answer: "False"
  },
  {
    question: "1.3 Gradient clipping is a technique used to prevent the exploding gradient problem in deep learning.",
    answer: "True"
  },
  {
    question: "2.1 The Nesterov Accelerated Gradient (NAG) optimization algorithm is an extension of momentum that incorporates the gradient's future position.",
    answer: "True"
  },
  {
    question: "2.2 The RMSProp optimization algorithm is specifically designed to resolve the diminishing learning rates problem in the AdaGrad algorithm.",
    answer: "True"
  },
  {
    question: "2.3 Weight decay is a form of L1 regularization that adds a penalty term to the loss function, discouraging large weight values and promoting sparsity.",
    answer: "False"
  },
  {
    question: "4.1 Dropout is a regularization technique that involves setting a random fraction of input units to zero during training to prevent overfitting.",
    answer: "True"
  },
  {
    question: "4.2 Data augmentation is a technique used to artificially increase the size of the training dataset by applying various transformations to the original data.",
    answer: "True"
  },
  {
    question: "4.3 A learning rate scheduler is a technique used to adjust the learning rate during training, usually increasing it as the number of training iterations increases.",
    answer: "False"
  },
  {
    question: "5.1 Convolutional Neural Networks (CNNs) employ weight sharing, which reduces the number of parameters in the model, making it more efficient to train.",
    answer: "True"
  },
  {
    question: "5.2 The use of dilated convolutions in a CNN architecture allows the model to have a larger receptive field without increasing the number of parameters significantly.",
    answer: "True"
  },
  {
    question: "5.3 The transformer architecture, which relies on self-attention mechanisms, has become the foundation for many state-of-the-art natural language processing models.",
    answer: "True"
  },
{
    question: "1.4 The perceptron learning algorithm is guaranteed to find a perfect linear separator for linearly separable data.",
    answer: "True"
  },
  {
    question: "1.5 In a feedforward neural network, information flows in both directions, forward and backward.",
    answer: "False"
  },
  {
    question: "1.6 The backpropagation algorithm is used to compute the gradients of the loss function with respect to each weight by using the chain rule.",
    answer: "True"
  },
  {
    question: "2.4 Autograd is an automatic differentiation system that can compute gradients for any differentiable function.",
    answer: "True"
  },
  {
    question: "2.5 In Stochastic Gradient Descent (SGD), the entire dataset is used for each update step.",
    answer: "False"
  },
  {
    question: "2.6 Mini-batch Gradient Descent is a compromise between Batch Gradient Descent and Stochastic Gradient Descent, using a subset of the data for each update step.",
    answer: "True"
  },
  {
    question: "3.4 The Rectified Linear Unit (ReLU) activation function is defined as f(x) = max(0, x).",
    answer: "True"
  },
  {
    question: "3.5 The cross-entropy loss is typically used for regression problems.",
    answer: "False"
  },
  {
    question: "3.6 Proper parameter initialization is important for ensuring the stability and efficiency of the training process.",
    answer: "True"
  },
  {
    question: "4.4 The Adam optimization algorithm combines the ideas of momentum and adaptive learning rates.",
    answer: "True"
  },
  {
    question: "4.5 L2 regularization is also known as ridge regression.",
    answer: "True"
  },
  {
    question: "4.6 Batch normalization is a technique used to improve the training of deep neural networks by normalizing the inputs to each layer.",
    answer: "True"
  },
  {
    question: "5.4 In a CNN, max-pooling layers are used to reduce the spatial dimensions of the feature maps.",
    answer: "True"
  },
  {
    question: "5.5 Fully connected layers in a CNN are responsible for learning spatial hierarchies of features.",
    answer: "False"
  },
  {
    question: "5.6 A 1x1 convolution is used to reduce the number of channels in a feature map without changing its spatial dimensions.",
    answer: "True"
  },
    {
    question: "1.1 The perceptron algorithm can be used to classify linearly inseparable data.",
    answer: "False"
  },
  {
    question: "1.2 In a multilayer feedforward network, information flows in both forward and backward directions, allowing the model to make predictions and update the weights accordingly.",
    answer: "False"
  },
  {
    question: "1.3 Backpropagation is an algorithm used to compute the gradients of the loss function with respect to each weight by using the chain rule.",
    answer: "True"
  },
  {
    question: "2.1 Autograd is a deep learning library that can automatically compute gradients for any differentiable function.",
    answer: "True"
  },
  {
    question: "2.2 Backpropagation is the process of computing the gradients of the loss function with respect to the model's parameters.",
    answer: "True"
  },
  {
    question: "2.3 In Stochastic Gradient Descent (SGD), the entire dataset is used for each update step.",
    answer: "False"
  },
  {
    question: "3.1 The ReLU activation function is defined as f(x) = max(0, x) and is commonly used in deep neural networks.",
    answer: "True"
  },
  {
    question: "3.2 Cross-entropy loss is commonly used for classification problems, while mean squared error loss is used for regression problems.",
    answer: "True"
  },
  {
    question: "3.3 Xavier initialization is a commonly used method for initializing the weights of deep neural networks.",
    answer: "True"
  },
  {
    question: "4.1 The Adam optimization algorithm is a variant of stochastic gradient descent that combines the ideas of momentum and adaptive learning rates.",
    answer: "True"
  },
  {
    question: "4.2 L1 regularization adds a penalty term to the loss function that discourages large weight values and promotes sparsity.",
    answer: "True"
  },
  {
    question: "4.3 Dropout is a regularization technique that involves setting a random fraction of input units to zero during training to prevent overfitting.",
    answer: "True"
  },
  {
    question: "5.1 In a convolutional neural network, convolutional layers are responsible for learning spatial hierarchies of features.",
    answer: "True"
  },
  {
    question: "5.2 Pooling layers in a CNN are used to increase the spatial resolution of the feature maps.",
    answer: "False"
  },
  {
    question: "5.3 The use of dilated convolutions in a CNN architecture allows the model to have a larger receptive field without increasing the number of parameters significantly.",
    answer: "True"
  },
  {
    question: "1.4 A multilayer feedforward network can be used to classify non-linearly separable data.",
    answer: "True"
  },
  {
    question: "1.5 In a multilayer feedforward network, information flows only in the forward direction, from input to output.",
    answer: "False"
  },
  {
    question: "2.4 The backpropagation algorithm is only used to compute the gradients of the loss function with respect to the output layer weights.",
    answer: "False"
  }
  ];

  function renderQuestions() {
    const container = document.getElementById('container');

    questions.forEach((question, index) => {
      const questionContainer = document.createElement('div');
      questionContainer.classList.add('question-container');

      const questionText = document.createElement('div');
      questionText.classList.add('question');
      questionText.textContent = `${index + 1}. ${question.question}`;
      questionContainer.appendChild(questionText);

      const trueButton = createAnswerButton('True', index, true);
      questionContainer.appendChild(trueButton);

      const falseButton = createAnswerButton('False', index, false);
      questionContainer.appendChild(falseButton);

      container.appendChild(questionContainer);
    });
  }

  function createAnswerButton(text, questionIndex, answer) {
    const button = document.createElement('button');
    button.classList.add('answer-button');
    button.textContent = text;

    button.addEventListener('click', () => {
      checkAnswer(questionIndex, answer, button);
    });

    return button;
  }

  function checkAnswer(questionIndex, userAnswer, button) {
    const correctAnswer = questions[questionIndex].answer === 'True';

    if (correctAnswer === userAnswer) {
      button.classList.remove('answer-button');
      button.classList.add('correct-button');
    } else {
      button.classList.remove('answer-button');
      button.classList.add('incorrect-button');
    }

    // Disable buttons after the user has made a choice
    const buttons = document.querySelectorAll(`[data-question="${questionIndex}"]`);
    buttons.forEach((button) => {
      button.disabled = true;
    });
  }

  document.addEventListener('DOMContentLoaded', renderQuestions);
</script>
</head>
<body>
  <h1>DEEP LEARNING QUIZ</h1>
  <div id="container"></div>
</body>
</html>
