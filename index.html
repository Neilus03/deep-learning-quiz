<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Deep Learning Questions</title>
<style>
  button {
    margin: 5px;
  }
</style>
<script>
  const questions = [
  {
    question: "1.1 A feedforward neural network with a single hidden layer and a sufficient number of hidden neurons can approximate any continuous function.",
    answer: "True"
  },
  {
    question: "1.2 Leaky ReLU activation functions are more likely to suffer from the vanishing gradient problem compared to sigmoid activation functions.",
    answer: "False"
  },
  {
    question: "1.3 Gradient clipping is a technique used to prevent the exploding gradient problem in deep learning.",
    answer: "True"
  },
  {
    question: "2.1 The Nesterov Accelerated Gradient (NAG) optimization algorithm is an extension of momentum that incorporates the gradient's future position.",
    answer: "True"
  },
  {
    question: "2.2 The RMSProp optimization algorithm is specifically designed to resolve the diminishing learning rates problem in the AdaGrad algorithm.",
    answer: "True"
  },
  {
    question: "2.3 Weight decay is a form of L1 regularization that adds a penalty term to the loss function, discouraging large weight values and promoting sparsity.",
    answer: "False"
  },
  {
    question: "3.1 The Gated Recurrent Unit (GRU) is a simplified version of the LSTM, with fewer parameters and a more efficient training process.",
    answer: "True"
  },
  {
    question: "3.2 In RNNs, the vanishing gradient problem can be alleviated by implementing techniques such as Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) layers.",
    answer: "True"
  },
  {
    question: "3.3 Bidirectional RNNs process input sequences in both forward and backward directions, enabling the model to better capture long-range dependencies.",
    answer: "True"
  },
  {
    question: "4.1 Dropout is a regularization technique that involves setting a random fraction of input units to zero during training to prevent overfitting.",
    answer: "True"
  },
  {
    question: "4.2 Data augmentation is a technique used to artificially increase the size of the training dataset by applying various transformations to the original data.",
    answer: "True"
  },
  {
    question: "4.3 A learning rate scheduler is a technique used to adjust the learning rate during training, usually increasing it as the number of training iterations increases.",
    answer: "False"
  },
  {
    question: "5.1 Convolutional Neural Networks (CNNs) employ weight sharing, which reduces the number of parameters in the model, making it more efficient to train.",
    answer: "True"
  },
  {
    question: "5.2 The use of dilated convolutions in a CNN architecture allows the model to have a larger receptive field without increasing the number of parameters significantly.",
    answer: "True"
  },
  {
    question: "5.3 The transformer architecture, which relies on self-attention mechanisms, has become the foundation for many state-of-the-art natural language processing models.",
    answer: "True"
  },
{
    question: "1.4 The perceptron learning algorithm is guaranteed to find a perfect linear separator for linearly separable data.",
    answer: "True"
  },
  {
    question: "1.5 In a feedforward neural network, information flows in both directions, forward and backward.",
    answer: "False"
  },
  {
    question: "1.6 The backpropagation algorithm is used to compute the gradients of the loss function with respect to each weight by using the chain rule.",
    answer: "True"
  },
  {
    question: "2.4 Autograd is an automatic differentiation system that can compute gradients for any differentiable function.",
    answer: "True"
  },
  {
    question: "2.5 In Stochastic Gradient Descent (SGD), the entire dataset is used for each update step.",
    answer: "False"
  },
  {
    question: "2.6 Mini-batch Gradient Descent is a compromise between Batch Gradient Descent and Stochastic Gradient Descent, using a subset of the data for each update step.",
    answer: "True"
  },
  {
    question: "3.4 The Rectified Linear Unit (ReLU) activation function is defined as f(x) = max(0, x).",
    answer: "True"
  },
  {
    question: "3.5 The cross-entropy loss is typically used for regression problems.",
    answer: "False"
  },
  {
    question: "3.6 Proper parameter initialization is important for ensuring the stability and efficiency of the training process.",
    answer: "True"
  },


  {
    question: "4.4 The Adam optimization algorithm combines the ideas of momentum and adaptive learning rates.",
    answer: "True"
  },
  {
    question: "4.5 L2 regularization is also known as ridge regression.",
    answer: "True"
  },
  {
    question: "4.6 Batch normalization is a technique used to improve the training of deep neural networks by normalizing the inputs to each layer.",
    answer: "True"
  },
  {
    question: "5.4 In a CNN, max-pooling layers are used to reduce the spatial dimensions of the feature maps.",
    answer: "True"
  },
  {
    question: "5.5 Fully connected layers in a CNN are responsible for learning spatial hierarchies of features.",
    answer: "False"
  },
  {
    question: "5.6 A 1x1 convolution is used to reduce the number of channels in a feature map without changing its spatial dimensions.",
    answer: "True"
  }
];


  function renderQuestions() {
    questions.forEach((question, index) => {
      const div = document.createElement('div');
      const p = document.createElement('p');
      p.textContent = `${index + 1}. ${question.question}`;
      div.appendChild(p);

      const trueButton = document.createElement('button');
      trueButton.textContent = 'True';
      trueButton.onclick = () => checkAnswer(index, trueButton, falseButton, true);
      div.appendChild(trueButton);

      const falseButton = document.createElement('button');
      falseButton.textContent = 'False';
      falseButton.onclick = () => checkAnswer(index, trueButton, falseButton, false);
      div.appendChild(falseButton);

      document.body.appendChild(div);
    });
  }

  function checkAnswer(questionIndex, trueButton, falseButton, userAnswer) {
    const correctAnswer = questions[questionIndex].answer === 'True';
    const selectedButton = userAnswer ? trueButton : falseButton;
    const otherButton = userAnswer ? falseButton : trueButton;

    if (correctAnswer === userAnswer) {
      selectedButton.style.backgroundColor = 'green';
    } else {
      selectedButton.style.backgroundColor = 'red';
    }

    // Disable buttons after the user has made a choice
    trueButton.disabled = true;
    falseButton.disabled = true;
  }

  document.addEventListener("DOMContentLoaded", renderQuestions);
</script>
</head>
<body>
</body>
</html>
